"""
Firebase Functions - Smart OCR RAG
Sá»­ dá»¥ng Google Vision OCR + OpenAI + Semantic Search Ä‘á»ƒ trÃ­ch xuáº¥t thÃ nh pháº§n sáº£n pháº©m
"""
import os
import json
import base64
import logging
from io import BytesIO

from firebase_functions import https_fn, options
from firebase_admin import initialize_app

# --- KHá»žI Táº O FIREBASE ---
initialize_app()

# --- LAZY LOADING CHO CÃC THÆ¯ VIá»†N Náº¶NG ---
# Sá»­ dá»¥ng lazy loading Ä‘á»ƒ tá»‘i Æ°u cold start
_embedder = None
_vision_client = None
_openai_client = None

def get_embedder():
    """Lazy load SentenceTransformer model"""
    global _embedder
    if _embedder is None:
        from sentence_transformers import SentenceTransformer
        logging.info("â³ Äang táº£i model Semantic...")
        _embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        logging.info("âœ… ÄÃ£ táº£i model xong!")
    return _embedder

def get_vision_client():
    """Lazy load Google Vision client"""
    global _vision_client
    if _vision_client is None:
        from google.cloud import vision
        _vision_client = vision.ImageAnnotatorClient()
    return _vision_client

def get_openai_client():
    """Lazy load OpenAI client"""
    global _openai_client
    if _openai_client is None:
        from openai import OpenAI
        # Láº¥y API key tá»« environment variable
        api_key = os.environ.get('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("OPENAI_API_KEY chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh!")
        _openai_client = OpenAI(api_key=api_key)
    return _openai_client


# ---------------------------------------------------------
# BÆ¯á»šC 1: GOOGLE VISION OCR (Láº¥y dá»¯ liá»‡u thÃ´)
# ---------------------------------------------------------
def get_ocr_data(image_content: bytes) -> list:
    """
    Sá»­ dá»¥ng Google Vision Ä‘á»ƒ OCR áº£nh
    Args:
        image_content: bytes cá»§a áº£nh
    Returns:
        List cÃ¡c tá»« vá»›i vá»‹ trÃ­ bounding box
    """
    from google.cloud import vision
    
    client = get_vision_client()
    image = vision.Image(content=image_content)
    
    response = client.document_text_detection(image=image)
    
    if not response.text_annotations:
        return []

    word_list = []
    ignore_chars = [",", ".", ":", ";", "|", "(", ")", "[", "]", "{", "}", "-", "*", "%"]
    
    for page in response.full_text_annotation.pages:
        for block in page.blocks:
            for paragraph in block.paragraphs:
                for word in paragraph.words:
                    word_text = ''.join([symbol.text for symbol in word.symbols])
                    box = [(v.x, v.y) for v in word.bounding_box.vertices]
                    is_noise = word_text in ignore_chars
                    
                    word_list.append({
                        "text": word_text, 
                        "box": box,
                        "is_noise": is_noise
                    })
    
    return word_list


# ---------------------------------------------------------
# BÆ¯á»šC 2: OPENAI ANALYSIS (Strict Prompt)
# ---------------------------------------------------------
def analyze_with_openai_strict(ocr_word_list: list) -> list:
    """
    Sá»­ dá»¥ng OpenAI Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  trÃ­ch xuáº¥t nguyÃªn liá»‡u
    """
    full_text = " ".join([w['text'] for w in ocr_word_list])
    
    client = get_openai_client()
    
    prompt = f"""
    Báº¡n lÃ  má»™t há»‡ thá»‘ng trÃ­ch xuáº¥t dá»¯ liá»‡u OCR chÃ­nh xÃ¡c (OCR Post-processor).
    
    INPUT: Má»™t Ä‘oáº¡n vÄƒn báº£n thÃ´ tá»« bao bÃ¬ sáº£n pháº©m.
    TASK: TrÃ­ch xuáº¥t danh sÃ¡ch cÃ¡c "ThÃ nh pháº§n nguyÃªn liá»‡u" (Ingredients).
    
    YÃŠU Cáº¦U Cá»°C Ká»² QUAN TRá»ŒNG (STRICT RULES):
    1. TÃ¡ch riÃªng tá»«ng nguyÃªn liá»‡u. Dáº¥u pháº©y (,) lÃ  dáº¥u hiá»‡u ngáº¯t quan trá»ng nháº¥t.
    2. LOáº I Bá»Ž hoÃ n toÃ n cÃ¡c con sá»‘ pháº§n trÄƒm vÃ  Ä‘á»‹nh lÆ°á»£ng (VÃ­ dá»¥: "BÆ¡ (1,9%)" -> Chá»‰ láº¥y "BÆ¡").
    3. LOáº I Bá»Ž cÃ¡c mÃ£ phá»¥ gia trong ngoáº·c náº¿u cÃ³ thá»ƒ tÃ¡ch rá»i.
    4. GIá»® NGUYÃŠN chÃ­nh táº£ cá»§a vÄƒn báº£n gá»‘c (ká»ƒ cáº£ lá»—i sai).
    5. Output tráº£ vá» JSON format: {{ "ingredients": ["item1", "item2", ...] }}
    
    VÄƒn báº£n Input:
    '''
    {full_text}
    '''
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"},
            temperature=0
        )
        data = json.loads(response.choices[0].message.content)
        return data.get("ingredients", [])
    except Exception as e:
        logging.error(f"Lá»—i OpenAI: {e}")
        return []


# ---------------------------------------------------------
# BÆ¯á»šC 3: SEMANTIC MAPPING RAG (Core Logic)
# ---------------------------------------------------------
def find_coordinates_semantic(target_phrases: list, ocr_word_list: list, threshold: float = 0.55) -> list:
    """
    Sá»­ dá»¥ng Vector Search Ä‘á»ƒ tÃ¬m vá»‹ trÃ­ cá»§a tá»«ng nguyÃªn liá»‡u trong áº£nh
    """
    from sentence_transformers import util
    import torch
    
    embedder = get_embedder()
    results = []

    # Táº¡o Corpus tá»« OCR data
    corpus_texts = []
    corpus_indices = []
    
    clean_indices = [i for i, w in enumerate(ocr_word_list) if not w['is_noise']]
    max_window_size = 5
    
    for window in range(1, max_window_size + 1):
        for i in range(len(clean_indices) - window + 1):
            current_indices = clean_indices[i : i + window]
            text_segment = " ".join([ocr_word_list[idx]['text'] for idx in current_indices])
            corpus_texts.append(text_segment)
            corpus_indices.append(current_indices)

    if not corpus_texts:
        return []

    # Encode corpus
    corpus_embeddings = embedder.encode(corpus_texts, convert_to_tensor=True)

    # TÃ¬m tá»«ng nguyÃªn liá»‡u
    for phrase in target_phrases:
        query_embedding = embedder.encode(phrase, convert_to_tensor=True)
        cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]
        
        best_score_idx = torch.argmax(cos_scores).item()
        best_score = cos_scores[best_score_idx].item()

        if best_score >= threshold:
            matched_text = corpus_texts[best_score_idx]
            matched_raw_indices = corpus_indices[best_score_idx]
            
            # Láº¥y bounding box
            matched_boxes = [ocr_word_list[idx]['box'] for idx in matched_raw_indices]
            
            all_x = [pt[0] for box in matched_boxes for pt in box]
            all_y = [pt[1] for box in matched_boxes for pt in box]
            
            final_box = [
                [min(all_x), min(all_y)], 
                [max(all_x), min(all_y)], 
                [max(all_x), max(all_y)], 
                [min(all_x), max(all_y)]
            ]
            
            results.append({
                "label": phrase,
                "matched_text": matched_text,
                "confidence": round(best_score, 3),
                "bounding_box": final_box
            })

    return results


# ---------------------------------------------------------
# FIREBASE FUNCTION ENDPOINT
# ---------------------------------------------------------
@https_fn.on_request(
    cors=options.CorsOptions(
        cors_origins=["*"],  # Cho phÃ©p táº¥t cáº£ origins, cÃ³ thá»ƒ restrict láº¡i
        cors_methods=["GET", "POST"]
    ),
    memory=options.MemoryOption.GB_2,  # 2GB RAM cho model ML
    timeout_sec=300,  # 5 phÃºt timeout
    region="asia-southeast1"  # Region Singapore
)
def smart_ocr_rag(req: https_fn.Request) -> https_fn.Response:
    """
    Firebase HTTP Function Ä‘á»ƒ xá»­ lÃ½ OCR + RAG
    
    Request Body (JSON):
    {
        "image_base64": "base64_encoded_image_string",
        "threshold": 0.6  (optional, default 0.6)
    }
    
    Hoáº·c gá»­i áº£nh trá»±c tiáº¿p qua multipart/form-data vá»›i field name lÃ  "image"
    """
    
    # Chá»‰ cháº¥p nháº­n POST
    if req.method != 'POST':
        return https_fn.Response(
            json.dumps({"error": "Method not allowed. Use POST."}),
            status=405,
            headers={"Content-Type": "application/json"}
        )
    
    try:
        image_content = None
        threshold = 0.6
        
        # Xá»­ lÃ½ multipart/form-data (upload file trá»±c tiáº¿p)
        if req.files and 'image' in req.files:
            file = req.files['image']
            image_content = file.read()
            threshold = float(req.form.get('threshold', 0.6))
        
        # Xá»­ lÃ½ JSON body (base64 image)
        elif req.is_json:
            data = req.get_json()
            
            if 'image_base64' not in data:
                return https_fn.Response(
                    json.dumps({"error": "Missing 'image_base64' field"}),
                    status=400,
                    headers={"Content-Type": "application/json"}
                )
            
            # Decode base64
            image_base64 = data['image_base64']
            # XÃ³a prefix náº¿u cÃ³ (data:image/png;base64,...)
            if ',' in image_base64:
                image_base64 = image_base64.split(',')[1]
            
            image_content = base64.b64decode(image_base64)
            threshold = float(data.get('threshold', 0.6))
        
        else:
            return https_fn.Response(
                json.dumps({"error": "Invalid request format. Use JSON or multipart/form-data"}),
                status=400,
                headers={"Content-Type": "application/json"}
            )
        
        # ===== Xá»¬ LÃ CHÃNH =====
        
        # 1. OCR
        logging.info("ðŸ” Báº¯t Ä‘áº§u OCR...")
        ocr_data = get_ocr_data(image_content)
        
        if not ocr_data:
            return https_fn.Response(
                json.dumps({
                    "success": False,
                    "error": "KhÃ´ng tÃ¬m tháº¥y text trong áº£nh"
                }),
                status=200,
                headers={"Content-Type": "application/json"}
            )
        
        # 2. PhÃ¢n tÃ­ch vá»›i OpenAI
        logging.info("ðŸ¤– Äang phÃ¢n tÃ­ch vá»›i AI...")
        ingredients = analyze_with_openai_strict(ocr_data)
        
        if not ingredients:
            # Tráº£ vá» raw OCR náº¿u khÃ´ng phÃ¢n tÃ­ch Ä‘Æ°á»£c
            raw_text = " ".join([w['text'] for w in ocr_data if not w['is_noise']])
            return https_fn.Response(
                json.dumps({
                    "success": True,
                    "ingredients": [],
                    "mappings": [],
                    "raw_text": raw_text,
                    "message": "KhÃ´ng tÃ¬m tháº¥y nguyÃªn liá»‡u. Tráº£ vá» raw OCR text."
                }),
                status=200,
                headers={"Content-Type": "application/json"}
            )
        
        # 3. Semantic Mapping
        logging.info("ðŸ”— Äang mapping vá»‹ trÃ­...")
        mappings = find_coordinates_semantic(ingredients, ocr_data, threshold)
        
        # 4. Táº¡o response
        response_data = {
            "success": True,
            "ingredients": ingredients,
            "mappings": mappings,
            "total_ocr_words": len(ocr_data),
            "matched_count": len(mappings),
            "threshold_used": threshold
        }
        
        logging.info(f"âœ… HoÃ n thÃ nh! TÃ¬m tháº¥y {len(ingredients)} nguyÃªn liá»‡u, mapped {len(mappings)}")
        
        return https_fn.Response(
            json.dumps(response_data, ensure_ascii=False),
            status=200,
            headers={"Content-Type": "application/json; charset=utf-8"}
        )
        
    except Exception as e:
        logging.error(f"âŒ Error: {str(e)}")
        return https_fn.Response(
            json.dumps({"success": False, "error": str(e)}),
            status=500,
            headers={"Content-Type": "application/json"}
        )


# ---------------------------------------------------------
# HEALTH CHECK ENDPOINT
# ---------------------------------------------------------
@https_fn.on_request(
    cors=options.CorsOptions(cors_origins=["*"], cors_methods=["GET"]),
    region="asia-southeast1"
)
def health_check(req: https_fn.Request) -> https_fn.Response:
    """Simple health check endpoint"""
    return https_fn.Response(
        json.dumps({
            "status": "healthy",
            "service": "smart-ocr-rag",
            "version": "1.0.0"
        }),
        status=200,
        headers={"Content-Type": "application/json"}
    )

