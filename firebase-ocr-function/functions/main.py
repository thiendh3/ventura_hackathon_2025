"""
Firebase Functions - Smart OCR RAG
Sá»­ dá»¥ng Google Vision OCR + OpenAI + Semantic Search Ä‘á»ƒ trÃ­ch xuáº¥t thÃ nh pháº§n sáº£n pháº©m
"""
import os
import json
import base64
import logging
from io import BytesIO

from firebase_functions import https_fn, options
from firebase_admin import initialize_app

# --- KHá»žI Táº O FIREBASE ---
initialize_app()

# --- LAZY LOADING CHO CÃC THÆ¯ VIá»†N Náº¶NG ---
# Sá»­ dá»¥ng lazy loading Ä‘á»ƒ tá»‘i Æ°u cold start
_embedder = None
_vision_client = None
_openai_client = None

def get_embedder():
    """Lazy load SentenceTransformer model"""
    global _embedder
    if _embedder is None:
        from sentence_transformers import SentenceTransformer
        logging.info("â³ Äang táº£i model Semantic...")
        _embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        logging.info("âœ… ÄÃ£ táº£i model xong!")
    return _embedder

def get_vision_client():
    """Lazy load Google Vision client"""
    global _vision_client
    if _vision_client is None:
        from google.cloud import vision
        _vision_client = vision.ImageAnnotatorClient()
    return _vision_client

def get_openai_client():
    """Lazy load OpenAI client"""
    global _openai_client
    if _openai_client is None:
        from openai import OpenAI
        # Láº¥y API key tá»« environment variable
        api_key = os.environ.get('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("OPENAI_API_KEY chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh!")
        _openai_client = OpenAI(api_key=api_key)
    return _openai_client


# ---------------------------------------------------------
# BÆ¯á»šC 1: GOOGLE VISION OCR (Láº¥y dá»¯ liá»‡u thÃ´)
# ---------------------------------------------------------
def get_ocr_data(image_content: bytes) -> list:
    """
    Sá»­ dá»¥ng Google Vision Ä‘á»ƒ OCR áº£nh
    Args:
        image_content: bytes cá»§a áº£nh
    Returns:
        List cÃ¡c tá»« vá»›i vá»‹ trÃ­ bounding box
    """
    from google.cloud import vision
    
    client = get_vision_client()
    image = vision.Image(content=image_content)
    
    response = client.document_text_detection(image=image)
    
    if not response.text_annotations:
        return []

    word_list = []
    ignore_chars = [",", ".", ":", ";", "|", "(", ")", "[", "]", "{", "}", "-", "*", "%"]
    
    for page in response.full_text_annotation.pages:
        for block in page.blocks:
            for paragraph in block.paragraphs:
                for word in paragraph.words:
                    word_text = ''.join([symbol.text for symbol in word.symbols])
                    box = [(v.x, v.y) for v in word.bounding_box.vertices]
                    is_noise = word_text in ignore_chars
                    
                    word_list.append({
                        "text": word_text, 
                        "box": box,
                        "is_noise": is_noise
                    })
    
    return word_list


# ---------------------------------------------------------
# BÆ¯á»šC 2: OPENAI ANALYSIS (Strict Prompt)
# ---------------------------------------------------------
def analyze_with_openai_strict(ocr_word_list: list) -> list:
    """
    Sá»­ dá»¥ng OpenAI Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  trÃ­ch xuáº¥t nguyÃªn liá»‡u
    """
    full_text = " ".join([w['text'] for w in ocr_word_list])
    
    client = get_openai_client()
    
    prompt = f"""
    Báº¡n lÃ  má»™t há»‡ thá»‘ng trÃ­ch xuáº¥t dá»¯ liá»‡u OCR chÃ­nh xÃ¡c (OCR Post-processor).
    
    INPUT: Má»™t Ä‘oáº¡n vÄƒn báº£n thÃ´ tá»« bao bÃ¬ sáº£n pháº©m.
    TASK: TrÃ­ch xuáº¥t danh sÃ¡ch cÃ¡c "ThÃ nh pháº§n nguyÃªn liá»‡u" (Ingredients).
    
    YÃŠU Cáº¦U Cá»°C Ká»² QUAN TRá»ŒNG (STRICT RULES):
    1. TÃ¡ch riÃªng tá»«ng nguyÃªn liá»‡u. Dáº¥u pháº©y (,) lÃ  dáº¥u hiá»‡u ngáº¯t quan trá»ng nháº¥t.
    2. LOáº I Bá»Ž hoÃ n toÃ n cÃ¡c con sá»‘ pháº§n trÄƒm vÃ  Ä‘á»‹nh lÆ°á»£ng (VÃ­ dá»¥: "BÆ¡ (1,9%)" -> Chá»‰ láº¥y "BÆ¡").
    3. LOáº I Bá»Ž cÃ¡c mÃ£ phá»¥ gia trong ngoáº·c náº¿u cÃ³ thá»ƒ tÃ¡ch rá»i.
    4. GIá»® NGUYÃŠN chÃ­nh táº£ cá»§a vÄƒn báº£n gá»‘c (ká»ƒ cáº£ lá»—i sai).
    5. Output tráº£ vá» JSON format: {{ "ingredients": ["item1", "item2", ...] }}
    
    VÄƒn báº£n Input:
    '''
    {full_text}
    '''
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"},
            temperature=0
        )
        data = json.loads(response.choices[0].message.content)
        return data.get("ingredients", [])
    except Exception as e:
        logging.error(f"Lá»—i OpenAI: {e}")
        return []


# ---------------------------------------------------------
# BÆ¯á»šC 2.5: PHÃ‚N TÃCH Rá»¦I RO Sá»¨C KHá»ŽE (Health Risk Analysis)
# ---------------------------------------------------------
def analyze_health_risks(ingredients: list, health_profile: dict) -> dict:
    """
    Sá»­ dá»¥ng OpenAI Ä‘á»ƒ phÃ¢n tÃ­ch rá»§i ro sá»©c khá»e dá»±a trÃªn ingredients vÃ  health profile
    
    Args:
        ingredients: Danh sÃ¡ch nguyÃªn liá»‡u Ä‘Ã£ trÃ­ch xuáº¥t
        health_profile: Há»“ sÆ¡ sá»©c khá»e cá»§a ngÆ°á»i dÃ¹ng
            {
                "medical_history": ["bá»‡nh 1", "bá»‡nh 2"],
                "allergy": ["dá»‹ á»©ng 1", "dá»‹ á»©ng 2"]
            }
    
    Returns:
        Dictionary chá»©a warnings, safe_ingredients, overall_recommendation
    """
    client = get_openai_client()
    
    # Format health profile for prompt
    medical_history = health_profile.get('medical_history', [])
    allergies = health_profile.get('allergy', [])
    
    medical_history_str = ", ".join(medical_history) if medical_history else "KhÃ´ng cÃ³"
    allergies_str = ", ".join(allergies) if allergies else "KhÃ´ng cÃ³"
    ingredients_str = ", ".join(ingredients)
    
    prompt = f"""
Báº¡n lÃ  má»™t BÃC SÄ¨ DINH DÆ¯á» NG vÃ  CHUYÃŠN GIA Dá»Š á»¨NG THá»°C PHáº¨M vá»›i kiáº¿n thá»©c y khoa sÃ¢u rá»™ng.

## NHIá»†M Vá»¤
PhÃ¢n tÃ­ch danh sÃ¡ch THÃ€NH PHáº¦N thá»±c pháº©m vÃ  xÃ¡c Ä‘á»‹nh thÃ nh pháº§n nÃ o cÃ³ thá»ƒ GÃ‚Y Háº I cho ngÆ°á»i dÃ¹ng dá»±a trÃªn Há»’ SÆ  Sá»¨C KHá»ŽE cá»§a há».

## Há»’ SÆ  Sá»¨C KHá»ŽE
- Tiá»n sá»­ bá»‡nh lÃ½: {medical_history_str}
- Dá»‹ á»©ng Ä‘Ã£ biáº¿t: {allergies_str}

## DANH SÃCH THÃ€NH PHáº¦N Cáº¦N PHÃ‚N TÃCH
{ingredients_str}

## YÃŠU Cáº¦U PHÃ‚N TÃCH (QUAN TRá»ŒNG)

1. **Nháº­n diá»‡n trá»±c tiáº¿p**: ThÃ nh pháº§n CÃ“ TRONG danh sÃ¡ch dá»‹ á»©ng
   - VÃ­ dá»¥: "háº£i sáº£n" bao gá»“m: tÃ´m, cua, má»±c, sÃ², á»‘c, cÃ¡...
   - VÃ­ dá»¥: "cÃ¡c loáº¡i Ä‘áº­u" bao gá»“m: Ä‘áº­u phá»™ng, Ä‘áº­u nÃ nh, Ä‘áº­u xanh, Ä‘áº­u Ä‘á»...
   - VÃ­ dá»¥: "gluten" bao gá»“m: bá»™t mÃ¬, lÃºa máº¡ch, yáº¿n máº¡ch...

2. **Nháº­n diá»‡n giÃ¡n tiáº¿p (Cross-reactivity)**: ThÃ nh pháº§n cÃ³ thá»ƒ GÃ‚Y PHáº¢N á»¨NG CHÃ‰O
   - VÃ­ dá»¥: Dá»‹ á»©ng latex â†’ cÃ³ thá»ƒ pháº£n á»©ng vá»›i chuá»‘i, bÆ¡, kiwi
   - VÃ­ dá»¥: Dá»‹ á»©ng Ä‘áº­u phá»™ng â†’ cÃ³ thá»ƒ pháº£n á»©ng vá»›i Ä‘áº­u tÆ°Æ¡ng, Ä‘áº­u xanh
   - VÃ­ dá»¥: Dá»‹ á»©ng sá»¯a bÃ² â†’ cÃ³ thá»ƒ pháº£n á»©ng vá»›i sá»¯a dÃª, sá»¯a cá»«u

3. **áº¢nh hÆ°á»Ÿng tiá»n sá»­ bá»‡nh**: ThÃ nh pháº§n KHÃ”NG Tá»T cho tÃ¬nh tráº¡ng bá»‡nh lÃ½
   - Gan nhiá»…m má»¡ â†’ háº¡n cháº¿ Ä‘Æ°á»ng, cháº¥t bÃ©o bÃ£o hÃ²a, rÆ°á»£u, fructose
   - Tiá»ƒu Ä‘Æ°á»ng â†’ háº¡n cháº¿ Ä‘Æ°á»ng, tinh bá»™t tinh cháº¿, carbohydrate Ä‘Æ¡n giáº£n
   - Cao huyáº¿t Ã¡p â†’ háº¡n cháº¿ muá»‘i (sodium), MSG, thá»±c pháº©m cháº¿ biáº¿n sáºµn
   - ViÃªm há»ng â†’ háº¡n cháº¿ Ä‘á»“ cay, Ä‘á»“ láº¡nh, Ä‘á»“ chiÃªn rÃ¡n, thá»±c pháº©m cÃ³ tÃ­nh axit
   - Gout â†’ háº¡n cháº¿ purine (thá»‹t Ä‘á», ná»™i táº¡ng, háº£i sáº£n)
   - Bá»‡nh tháº­n â†’ háº¡n cháº¿ protein, potassium, phosphorus

## OUTPUT FORMAT (JSON)
{{
  "warnings": [
    {{
      "ingredient": "TÃªn thÃ nh pháº§n gá»‘c tá»« danh sÃ¡ch",
      "risk_score": 0.95,
      "warning_type": "allergy/cross_reactivity/medical_condition",
      "summary": "TÃ³m táº¯t ngáº¯n gá»n lÃ½ do cáº£nh bÃ¡o",
      "scientific_explanation": "Giáº£i thÃ­ch CHI TIáº¾T vá» máº·t y khoa/sinh há»c: tÃªn khoa há»c cá»§a thÃ nh pháº§n, cÆ¡ cháº¿ sinh há»c táº¡i sao gÃ¢y háº¡i, cÃ¡c protein/há»£p cháº¥t cá»¥ thá»ƒ liÃªn quan, quÃ¡ trÃ¬nh pháº£n á»©ng trong cÆ¡ thá»ƒ",
      "potential_effects": ["TÃ¡c Ä‘á»™ng 1", "TÃ¡c Ä‘á»™ng 2", "TÃ¡c Ä‘á»™ng 3"],
      "recommendation": "Lá»i khuyÃªn cá»¥ thá»ƒ vÃ  thá»±c táº¿ cho bá»‡nh nhÃ¢n"
    }}
  ],
  "safe_ingredients": ["Danh sÃ¡ch cÃ¡c thÃ nh pháº§n AN TOÃ€N khÃ´ng cÃ³ váº¥n Ä‘á»"],
  "overall_recommendation": "ÄÃ¡nh giÃ¡ tá»•ng thá»ƒ: sáº£n pháº©m nÃ y cÃ³ AN TOÃ€N hay KHÃ”NG AN TOÃ€N cho bá»‡nh nhÃ¢n, kÃ¨m lá»i khuyÃªn cuá»‘i cÃ¹ng"
}}

## QUY Táº®C Báº®T BUá»˜C
- Chá»‰ tráº£ vá» JSON thuáº§n tÃºy, khÃ´ng cÃ³ text giáº£i thÃ­ch bÃªn ngoÃ i
- TOÃ€N Bá»˜ ná»™i dung PHáº¢I viáº¿t báº±ng TIáº¾NG VIá»†T CÃ“ Dáº¤U Ä‘áº§y Ä‘á»§
- risk_score: Äiá»ƒm sá»‘ Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ nguy hiá»ƒm trong khoáº£ng [0, 1], trong Ä‘Ã³:
  * 0.8 - 1.0 = Cá»±c ká»³ nguy hiá»ƒm (dá»‹ á»©ng trá»±c tiáº¿p, cÃ³ thá»ƒ gÃ¢y sá»‘c pháº£n vá»‡)
  * 0.6 - 0.79 = Nguy hiá»ƒm cao (pháº£n á»©ng chÃ©o máº¡nh, áº£nh hÆ°á»Ÿng nghiÃªm trá»ng Ä‘áº¿n bá»‡nh lÃ½)
  * 0.4 - 0.59 = Nguy hiá»ƒm trung bÃ¬nh (áº£nh hÆ°á»Ÿng tiá»n sá»­ bá»‡nh, cáº§n háº¡n cháº¿)
  * 0.2 - 0.39 = Nguy hiá»ƒm tháº¥p (cáº§n tháº­n trá»ng, theo dÃµi)
  * 0.0 - 0.19 = Ráº¥t tháº¥p (áº£nh hÆ°á»Ÿng nháº¹, cÃ³ thá»ƒ sá»­ dá»¥ng vá»›i lÆ°á»£ng nhá»)
- Giáº£i thÃ­ch khoa há»c pháº£i chuyÃªn sÃ¢u nhÆ°ng váº«n dá»… hiá»ƒu cho ngÆ°á»i khÃ´ng cÃ³ chuyÃªn mÃ´n y khoa
- Náº¿u KHÃ”NG cÃ³ thÃ nh pháº§n nÃ o cÃ³ váº¥n Ä‘á», tráº£ vá» warnings = [] vÃ  overall_recommendation tÃ­ch cá»±c
- Chá»‰ cáº£nh bÃ¡o nhá»¯ng thÃ nh pháº§n THá»°C Sá»° cÃ³ trong danh sÃ¡ch, khÃ´ng tá»± thÃªm thÃ nh pháº§n má»›i
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"},
            temperature=0
        )
        data = json.loads(response.choices[0].message.content)
        return {
            "warnings": data.get("warnings", []),
            "safe_ingredients": data.get("safe_ingredients", []),
            "overall_recommendation": data.get("overall_recommendation", "")
        }
    except Exception as e:
        logging.error(f"Lá»—i phÃ¢n tÃ­ch health risks: {e}")
        return {
            "warnings": [],
            "safe_ingredients": ingredients,
            "overall_recommendation": f"KhÃ´ng thá»ƒ phÃ¢n tÃ­ch rá»§i ro sá»©c khá»e: {str(e)}"
        }


# ---------------------------------------------------------
# BÆ¯á»šC 3: SEMANTIC MAPPING RAG (Core Logic)
# ---------------------------------------------------------
def find_coordinates_semantic(target_phrases: list, ocr_word_list: list, threshold: float = 0.55) -> list:
    """
    Sá»­ dá»¥ng Vector Search Ä‘á»ƒ tÃ¬m vá»‹ trÃ­ cá»§a tá»«ng nguyÃªn liá»‡u trong áº£nh
    """
    from sentence_transformers import util
    import torch
    
    embedder = get_embedder()
    results = []

    # Táº¡o Corpus tá»« OCR data
    corpus_texts = []
    corpus_indices = []
    
    clean_indices = [i for i, w in enumerate(ocr_word_list) if not w['is_noise']]
    max_window_size = 5
    
    for window in range(1, max_window_size + 1):
        for i in range(len(clean_indices) - window + 1):
            current_indices = clean_indices[i : i + window]
            text_segment = " ".join([ocr_word_list[idx]['text'] for idx in current_indices])
            corpus_texts.append(text_segment)
            corpus_indices.append(current_indices)

    if not corpus_texts:
        return []

    # Encode corpus
    corpus_embeddings = embedder.encode(corpus_texts, convert_to_tensor=True)

    # TÃ¬m tá»«ng nguyÃªn liá»‡u
    for phrase in target_phrases:
        query_embedding = embedder.encode(phrase, convert_to_tensor=True)
        cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]
        
        best_score_idx = torch.argmax(cos_scores).item()
        best_score = cos_scores[best_score_idx].item()

        if best_score >= threshold:
            matched_text = corpus_texts[best_score_idx]
            matched_raw_indices = corpus_indices[best_score_idx]
            
            # Láº¥y bounding box
            matched_boxes = [ocr_word_list[idx]['box'] for idx in matched_raw_indices]
            
            all_x = [pt[0] for box in matched_boxes for pt in box]
            all_y = [pt[1] for box in matched_boxes for pt in box]
            
            final_box = [
                [min(all_x), min(all_y)], 
                [max(all_x), min(all_y)], 
                [max(all_x), max(all_y)], 
                [min(all_x), max(all_y)]
            ]
            
            results.append({
                "label": phrase,
                "matched_text": matched_text,
                "confidence": round(best_score, 3),
                "bounding_box": final_box
            })

    return results


# ---------------------------------------------------------
# FIREBASE FUNCTION ENDPOINT
# ---------------------------------------------------------
@https_fn.on_request(
    cors=options.CorsOptions(
        cors_origins=["*"],  # Cho phÃ©p táº¥t cáº£ origins, cÃ³ thá»ƒ restrict láº¡i
        cors_methods=["GET", "POST"]
    ),
    memory=options.MemoryOption.GB_2,  # 2GB RAM cho model ML
    timeout_sec=300,  # 5 phÃºt timeout
    region="asia-southeast1"  # Region Singapore
)
def smart_ocr_rag(req: https_fn.Request) -> https_fn.Response:
    """
    Firebase HTTP Function Ä‘á»ƒ xá»­ lÃ½ OCR + RAG + Health Analysis
    
    Request Body (JSON):
    {
        "image_base64": "base64_encoded_image_string",
        "threshold": 0.6  (optional, default 0.6),
        "health_profile": {
            "medical_history": ["bá»‡nh 1", "bá»‡nh 2"],
            "allergy": ["dá»‹ á»©ng 1", "dá»‹ á»©ng 2"]
        }
    }
    
    Hoáº·c gá»­i qua multipart/form-data:
    - image: file áº£nh
    - health_profile: JSON string cá»§a health profile
    - threshold: optional
    """
    
    # Chá»‰ cháº¥p nháº­n POST
    if req.method != 'POST':
        return https_fn.Response(
            json.dumps({"error": "Method not allowed. Use POST."}),
            status=405,
            headers={"Content-Type": "application/json"}
        )
    
    try:
        image_content = None
        threshold = 0.6
        health_profile = None
        
        # Xá»­ lÃ½ multipart/form-data (upload file trá»±c tiáº¿p)
        if req.files and 'image' in req.files:
            file = req.files['image']
            image_content = file.read()
            threshold = float(req.form.get('threshold', 0.6))
            
            # Parse health_profile tá»« form data
            health_profile_str = req.form.get('health_profile')
            if health_profile_str:
                try:
                    health_profile = json.loads(health_profile_str)
                except json.JSONDecodeError:
                    return https_fn.Response(
                        json.dumps({"error": "Invalid health_profile JSON format"}),
                        status=400,
                        headers={"Content-Type": "application/json"}
                    )
        
        # Xá»­ lÃ½ JSON body (base64 image)
        elif req.is_json:
            data = req.get_json()
            
            if 'image_base64' not in data:
                return https_fn.Response(
                    json.dumps({"error": "Missing 'image_base64' field"}),
                    status=400,
                    headers={"Content-Type": "application/json"}
                )
            
            # Decode base64
            image_base64 = data['image_base64']
            # XÃ³a prefix náº¿u cÃ³ (data:image/png;base64,...)
            if ',' in image_base64:
                image_base64 = image_base64.split(',')[1]
            
            image_content = base64.b64decode(image_base64)
            threshold = float(data.get('threshold', 0.6))
            health_profile = data.get('health_profile')
        
        else:
            return https_fn.Response(
                json.dumps({"error": "Invalid request format. Use JSON or multipart/form-data"}),
                status=400,
                headers={"Content-Type": "application/json"}
            )
        
        # Validate health_profile (báº¯t buá»™c)
        if not health_profile:
            return https_fn.Response(
                json.dumps({
                    "error": "Missing 'health_profile' field",
                    "required_format": {
                        "medical_history": ["bá»‡nh 1", "bá»‡nh 2"],
                        "allergy": ["dá»‹ á»©ng 1", "dá»‹ á»©ng 2"]
                    }
                }),
                status=400,
                headers={"Content-Type": "application/json"}
            )
        
        # Validate health_profile structure
        if not isinstance(health_profile.get('medical_history'), list):
            health_profile['medical_history'] = []
        if not isinstance(health_profile.get('allergy'), list):
            health_profile['allergy'] = []
        
        # ===== Xá»¬ LÃ CHÃNH =====
        
        # 1. OCR
        logging.info("ðŸ” Báº¯t Ä‘áº§u OCR...")
        ocr_data = get_ocr_data(image_content)
        
        if not ocr_data:
            return https_fn.Response(
                json.dumps({
                    "success": False,
                    "error": "KhÃ´ng tÃ¬m tháº¥y text trong áº£nh"
                }),
                status=200,
                headers={"Content-Type": "application/json"}
            )
        
        # 2. PhÃ¢n tÃ­ch vá»›i OpenAI Ä‘á»ƒ trÃ­ch xuáº¥t nguyÃªn liá»‡u
        logging.info("ðŸ¤– Äang phÃ¢n tÃ­ch vá»›i AI...")
        ingredients = analyze_with_openai_strict(ocr_data)
        
        if not ingredients:
            # Tráº£ vá» raw OCR náº¿u khÃ´ng phÃ¢n tÃ­ch Ä‘Æ°á»£c
            raw_text = " ".join([w['text'] for w in ocr_data if not w['is_noise']])
            return https_fn.Response(
                json.dumps({
                    "success": True,
                    "ingredients": [],
                    "health_warnings": [],
                    "safe_ingredients": [],
                    "risk_summary": {
                        "max_risk_score": 0,
                        "avg_risk_score": 0,
                        "critical_risk_count": 0,
                        "high_risk_count": 0,
                        "medium_risk_count": 0,
                        "low_risk_count": 0,
                        "very_low_risk_count": 0,
                        "total_warnings": 0,
                        "overall_recommendation": "KhÃ´ng tÃ¬m tháº¥y nguyÃªn liá»‡u Ä‘á»ƒ phÃ¢n tÃ­ch."
                    },
                    "mappings": [],
                    "raw_text": raw_text,
                    "message": "KhÃ´ng tÃ¬m tháº¥y nguyÃªn liá»‡u. Tráº£ vá» raw OCR text.",
                    "user_profile": health_profile
                }, ensure_ascii=False),
                status=200,
                headers={"Content-Type": "application/json; charset=utf-8"}
            )
        
        # 3. PhÃ¢n tÃ­ch rá»§i ro sá»©c khá»e
        logging.info("ðŸ¥ Äang phÃ¢n tÃ­ch rá»§i ro sá»©c khá»e...")
        health_analysis = analyze_health_risks(ingredients, health_profile)
        
        # 4. Semantic Mapping
        logging.info("ðŸ”— Äang mapping vá»‹ trÃ­...")
        mappings = find_coordinates_semantic(ingredients, ocr_data, threshold)
        
        # 5. TÃ­nh toÃ¡n risk summary dá»±a trÃªn risk_score
        warnings = health_analysis.get("warnings", [])
        
        # PhÃ¢n loáº¡i theo risk_score
        critical_risk_count = len([w for w in warnings if w.get("risk_score", 0) >= 0.8])  # 0.8-1.0
        high_risk_count = len([w for w in warnings if 0.6 <= w.get("risk_score", 0) < 0.8])  # 0.6-0.79
        medium_risk_count = len([w for w in warnings if 0.4 <= w.get("risk_score", 0) < 0.6])  # 0.4-0.59
        low_risk_count = len([w for w in warnings if 0.2 <= w.get("risk_score", 0) < 0.4])  # 0.2-0.39
        very_low_risk_count = len([w for w in warnings if w.get("risk_score", 0) < 0.2])  # 0-0.19
        
        # TÃ­nh max vÃ  avg risk score
        risk_scores = [w.get("risk_score", 0) for w in warnings]
        max_risk_score = max(risk_scores) if risk_scores else 0
        avg_risk_score = sum(risk_scores) / len(risk_scores) if risk_scores else 0
        
        # 6. Táº¡o response
        response_data = {
            "success": True,
            "ingredients": ingredients,
            "health_warnings": warnings,
            "safe_ingredients": health_analysis.get("safe_ingredients", []),
            "risk_summary": {
                "max_risk_score": round(max_risk_score, 2),
                "avg_risk_score": round(avg_risk_score, 2),
                "critical_risk_count": critical_risk_count,
                "high_risk_count": high_risk_count,
                "medium_risk_count": medium_risk_count,
                "low_risk_count": low_risk_count,
                "very_low_risk_count": very_low_risk_count,
                "total_warnings": len(warnings),
                "overall_recommendation": health_analysis.get("overall_recommendation", "")
            },
            "mappings": mappings,
            "total_ocr_words": len(ocr_data),
            "matched_count": len(mappings),
            "threshold_used": threshold,
            "user_profile": {
                "allergies_checked": health_profile.get("allergy", []),
                "conditions_checked": health_profile.get("medical_history", [])
            }
        }
        
        logging.info(f"âœ… HoÃ n thÃ nh! TÃ¬m tháº¥y {len(ingredients)} nguyÃªn liá»‡u, {len(warnings)} cáº£nh bÃ¡o")
        
        return https_fn.Response(
            json.dumps(response_data, ensure_ascii=False),
            status=200,
            headers={"Content-Type": "application/json; charset=utf-8"}
        )
        
    except Exception as e:
        logging.error(f"âŒ Error: {str(e)}")
        return https_fn.Response(
            json.dumps({"success": False, "error": str(e)}),
            status=500,
            headers={"Content-Type": "application/json"}
        )


# ---------------------------------------------------------
# HEALTH CHECK ENDPOINT
# ---------------------------------------------------------
@https_fn.on_request(
    cors=options.CorsOptions(cors_origins=["*"], cors_methods=["GET"]),
    region="asia-southeast1"
)
def health_check(req: https_fn.Request) -> https_fn.Response:
    """Simple health check endpoint"""
    return https_fn.Response(
        json.dumps({
            "status": "healthy",
            "service": "smart-ocr-rag",
            "version": "1.0.0"
        }),
        status=200,
        headers={"Content-Type": "application/json"}
    )
